## 1.Spring Ai 的全面概述



## 2.Spring Ai 的基本功能

-   支持所有主要 [的 AI 模型提供商 ](https://docs.spring.io/spring-ai/reference/api/index.html)，例如 `Anthropic、OpenAI、Microsoft、Amazon、Google 和 Ollama`
-   支持的模型类型包括：

    *   [Chat Completion 聊天完成](https://docs.spring.io/spring-ai/reference/api/chatmodel.html)

    *   [Embedding 嵌入](https://docs.spring.io/spring-ai/reference/api/embeddings.html)

    *   [Text to Image 文本到图像](https://docs.spring.io/spring-ai/reference/api/imageclient.html)

    *   [Audio Transcription 音频转录](https://docs.spring.io/spring-ai/reference/api/audio/transcriptions.html)

    *   [Text to Speech 文本到语音](https://docs.spring.io/spring-ai/reference/api/audio/speech.html)

    *   [Moderation 适度](https://docs.spring.io/spring-ai/reference/api/index.html#api/moderation)
-   支持跨 `AI` 提供商的同步处理 `API` 和流式处理 `API` 选项，并且可移植，还可以访问特定于模型的高级功能（说白了就是有些 `AI` 厂家提供了一些独有的功能）
-   [结构化输出](https://docs.spring.io/spring-ai/reference/api/structured-output-converter.html)，从 `AI` 模型输出到 `POJO` 的映射
-   支持所有主要的 [矢量数据库提供商](https://docs.spring.io/spring-ai/reference/api/vectordbs.html)，例如 `Apache Cassandra、Azure Vector Search、Chroma、Milvus、MongoDB Atlas、Neo4j、Oracle、PostgreSQL/PGVector、PineCone、Qdrant、Redis、Weaviate`
-   ...

## 3.Spring Ai 的使用教程

### 3.1.基本知识

#### 3.1.1.模型

#### 3.1.2.提示

#### 3.1.3.嵌入

#### 3.1.4.令牌

#### 3.1.5.结构化输出

#### 3.1.6.自定义模型

一、微调（Fine Tuning）是啥？

**本质：改模型本身，把它“重新训练”成你的私有模型。**

*   就像拿一个 GPT 模型，然后继续训练它，让它学会你自己的数据。
*   会**直接修改模型内部的权重参数**。
*   缺点：
    *   非常烧 GPU（资源消耗大）
    *   非常烧脑（工程复杂）
    *   普通人基本搞不定

🧠 类比：你想让一个老师专门懂你家的家谱，直接给他“洗脑重教一遍”。

二、提示填充 / Prompt Stuffing 是啥？

**本质：不改模型，而是“骗它”在对话中去理解你的数据。**

*   你把自己的知识，**作为 prompt（提示）拼进去**
*   模型不需要训练，它只是**临时参考上下文**
*   技术名词叫 **RAG（Retrieval Augmented Generation）**

🧠 类比：你不教老师新知识，但在问问题时把参考资料放在他面前，他读了再回答你。

三、**[工具调用 ](https://docs.spring.io/spring-ai/reference/concepts.html#concept-fc)**：该技术允许注册将大型语言模型连接到外部系统 API 的工具（用户定义的服务）。Spring AI 大大简化了您需要编写以支持[工具调用](https://docs.spring.io/spring-ai/reference/api/tools.html)的代码。

四、**RAG**（检索增强生成）就是： 把你的资料（PDF、文档、网页、代码）提前整理好 → 存到向量数据库里 →
 当用户提问时，找出“相关资料片段” → 和问题一起塞给大语言模型回答。

------

🔍 一段段解释：

------

📌 原文：

>   A technique termed Retrieval Augmented Generation (RAG) has emerged...

**翻译白话：**
 RAG 是一种新方法，它的目标是：
 **当模型回答问题时，先“从你自己的资料里查一下”，再回答。**

------

📌 原文：

>   The approach involves a batch processing style programming model...

**白话：**
 RAG 的准备工作是“批处理式”的：

*   把你的文档（比如 PDF、网页、txt）读出来
*   拆成一小段一小段
*   生成向量（embedding）后写进**向量数据库**

这个过程就像做 ETL：提取、转换、加载。

------

📌 原文：

>   One of the most important transformations is to split the original document...

**白话：**
 文档不能乱拆，要注意**语义边界**，比如：

*   一段话不能拆到一半
*   表格不能拆坏
*   代码不能拆在函数中间

然后再把这些段落**继续拆小一点**，因为模型能看的 token 是有限的。

------

📌 原文：

>   When a user’s question is to be answered...

**白话：**
 用户提问时：

1.  用向量数据库查“哪几段资料和问题最相关”
2.  把这些相关资料 + 用户的问题，组成 prompt
3.  一起发给 GPT，让它回答

------

💡 为什么用向量数据库？

因为普通数据库只能查关键字（比如你搜“苹果”就只能找“苹果”）。

而向量数据库可以查“意思相近”的，比如：

*   你问“苹果价格”
*   它能找到“水果行情”“Apple 报价”这些内容
*   因为它查的是**语义相似度**，不是关键字！

------

🧠 总结图解（概念流程）：

```
[文档] → 拆小段 → 做 embedding → 存向量库
                                            ↓
用户提问 → 做 embedding → 查相似段 → 拼成 prompt → 发给 GPT
```

#### 3.1.7.评估回答效果

这段话本质上讲的是：**怎么判断 AI 回答得好不好？**

我给你**拆开+翻译成白话**，看完你就懂了：

------

✅ 总结一句话：

>   想知道 AI 回答得靠不靠谱？就得**对它的回答进行“评估”**，而 Spring AI 提供了对应的 API 工具来帮你这么做。

------

🔍 一段一段翻译解释：

------

📌 原文：

>   This evaluation process involves analyzing whether the generated response aligns with the user’s intent and the context of the query.
>    此评估过程包括分析生成的响应是否与用户的意图和查询的上下文一致。

**白话：**
 评估就是看 AI 的回答：

*   有没有答对问题（跟用户的意思对得上）
*   有没有跟上下文搭上（不是瞎说）

------

📌 原文：

>   Metrics such as relevance, coherence, and factual correctness...
>    相关性、连贯性和事实正确性等指标...

**白话：**
 评估时重点看这几方面：

*   **相关性**：答的是不是你问的
*   **连贯性**：前后有没有逻辑
*   **事实正确性**：是不是胡编乱造

------

📌 原文：

>   One approach involves presenting both the user’s request and the AI model’s response to the model...
>    一种方法是把用户问题 + AI 回答再交给 AI 来判断对不对。

**白话：**
 让 AI 自己审查自己：
 “你看，这是问题，这是回答，你觉得答得对吗？”
 这叫**自我评估（self-reflection）**方式。

------

📌 原文：

>   Leveraging the information stored in the vector database...
>    利用向量数据库中存的资料可以增强评估过程。

**白话：**
 如果你之前用了 RAG 技术：
 那你有一个“资料库”存着相关资料，
 可以用这些资料来辅助判断：AI 回答是不是和资料一致。

------

📌 原文：

>   The Spring AI project provides an Evaluator API...

**白话：**
 Spring AI 框架已经帮你封装好了“评估用的接口”（Evaluator API），
 你可以用它来自动判断 AI 的回答质量。

------

🧠 举个例子说明整个流程：

```txt
用户提问：React 里怎么用 useEffect？

RAG 检索到的资料：useEffect 是 React 的副作用钩子...

AI 回答：useEffect 用于在组件生命周期中执行副作用...

→ 评估阶段：
  - 答案是否跟资料一致？（是 ✅）
  - 答案是否答非所问？（没有 ❌）
  - 答案逻辑清晰、语法通顺？（是 ✅）
  → 结论：回答质量高
```

------

你可以把它理解为：
 **让程序自己当“审稿人”**，去打分或者判断 AI 的回答好不好。

要不要我给你写个 Spring AI 的评估代码样例？你直接能测。

### 3.2.依赖安装

`Spring Ai` 的核心依赖分为里程版本和快照版本，这里我们采用更加稳定的里程版本。

```xml
<dependencyManagement>
    <dependencies>
        <dependency>
            <groupId>org.springframework.ai</groupId>
            <artifactId>spring-ai-bom</artifactId>
            <version>1.0.0-SNAPSHOT</version>
            <type>pom</type>
            <scope>import</scope>
        </dependency>
    </dependencies>
</dependencyManagement>

```

### 3.3.接入模型

#### 3.3.1.聊天模型

这里我们开始我们第一次的实践，我决定使用 `Spring Ai + Ollama` 并且拉取聊天模型开始，无他因为更好入门，在引入 `Spring Ai` 后就需要引入支持 `Ollama` 的依赖。

```xml
<dependency>
   <groupId>org.springframework.ai</groupId>
   <artifactId>spring-ai-starter-model-ollama</artifactId>
</dependency>
```

然后配置我们的应用配置文件。



#### 3.3.2.嵌入模型



#### 3.3.3.图像模型



#### 3.3.4.音频模型



#### 3.3.5.审核模型



### 3.4.矢量数库

### 3.3.结构输出

### 3.6.自定模型

#### 3.6.1.参数微调

#### 3.6.2.提示填充

#### 3.6.3.工具调用

### 3.7.模型评估



